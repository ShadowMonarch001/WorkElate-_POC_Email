# âš¡ WorkElate: Living Project Inbox  

WorkElate is an **AI-powered project management experiment** that transforms a static vector database into a **â€œlivingâ€ project record**.  

Unlike traditional RAG (Retrieval-Augmented Generation) systems that only *read* data, WorkElate enables **real-time project updates via natural language**, re-indexing changes instantly to keep the system state fresh and queryable.

---

## ğŸš€ The Concept: â€œLivingâ€ RAG

Most AI assistants operate in **read-only mode**. WorkElate introduces a **closed feedback loop**, allowing the AI to both read and mutate structured project state.

### ğŸ” 1. Intent Classification  
The system determines whether the user is:
- Asking a question (Query)
- Providing a project update (Mutation)

### ğŸ”„ 2. State Modification  
If it's an update:
- Fetch existing project metadata from Pinecone  
- Inject new update into structured context  
- Re-embed the updated project record  
- Upsert back into Pinecone  

This creates a **mutable vector state**.

### ğŸ§  3. Contextual Retrieval  
For queries:
- Retrieve the most recent vector state  
- Pass enriched context into Llama 3.3  
- Generate a professional, up-to-date summary  

The result:  
A vector database that behaves like a **living project memory** instead of static storage.

---

## ğŸ› ï¸ Tech Stack

| Layer | Technology |
|-------|------------|
| **Frontend** | Streamlit |
| **LLM** | Groq (Llama 3.3 70B) |
| **Vector Database** | Pinecone |
| **Orchestration** | LangChain |
| **Embeddings** | OpenAI `text-embedding-3-small` |

---

## ğŸ“‚ Project Structure


.
â”œâ”€â”€ app.py # Main Streamlit application (UI)
â”œâ”€â”€ ingest.py # Script to push data.json to Pinecone
â”œâ”€â”€ data.json # Initial seed data for project records
â”œâ”€â”€ .env # API Keys (OpenAI, Pinecone, Groq)
â”œâ”€â”€ requirements.txt # Project dependencies
â””â”€â”€ README.md # Documentation


---

## âš™ï¸ Setup & Installation

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/your-username/workelate.git
cd workelate
```
2ï¸âƒ£ Install Dependencies
pip install -r requirements.txt
3ï¸âƒ£ Configure Environment Variables

Create a .env file in the root directory:

OPENAI_API_KEY=your_openai_key
GROQ_API_KEY=your_groq_key
PINECONE_API_KEY=your_pinecone_key
4ï¸âƒ£ Ingest Initial Data

Ensure data.json is populated, then initialize your Pinecone index:

python ingest.py
5ï¸âƒ£ Run the Application
streamlit run app.py
ğŸ’¡ Usage
ğŸ“ Updating a Project

Enter a Project ID (e.g., P-ALPHA-01) and provide a natural language update:

"The frontend is done"

Internal Flow:

Project record is retrieved

Update appended to the Details field

New embedding generated

Updated vector upserted into Pinecone

Your project state is now mutated and persisted.

ğŸ” Querying a Project

Ask contextual questions like:

"What is the current status?"

The system:

Retrieves the latest vector

Injects updated context into Llama 3.3

Returns a professional summary

ğŸ§© Why This Matters

WorkElate demonstrates how to move beyond static RAG into:

Stateful AI systems

Mutable vector memory

Real-time semantic re-indexing

Natural language-driven project management

Itâ€™s a practical exploration of stateful AI applications using modern LLM infrastructure.


If you found this interesting, consider â­ starring the repo and experimenting with your own â€œLiving RAGâ€ workflows.
